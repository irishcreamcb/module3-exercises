\documentclass{article}
\usepackage{amsmath}
\usepackage{amsthm,amssymb}
\usepackage[a4paper,left=25mm,right=25mm,top=30mm,bottom=30mm]{geometry}
\usepackage{fancyhdr}
\usepackage{titlesec}
\usepackage{enumerate} 
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{tikz} 
\usepackage{cancel}
\usepackage{parskip}
\usepackage[condensed,light,math]{iwona}
\usepackage[T1]{fontenc}
\usepackage{booktabs}

\title{probability exercises}
\author{emilianna louise abundo limlengco} 
\date{\today} 

\fboxsep=4pt
\RenewDocumentCommand{\footnoterule}{}{\vfill\kern-3pt \hrule width 0.4\columnwidth\kern2.6pt} %yoinked from LSE

\RenewDocumentCommand{\labelitemi}{}{$\rightarrow$}
\RenewDocumentCommand{\labelenumi}{}{\colorbox{pink}{\textbf{\arabic{enumi}}}}
\RenewDocumentCommand{\labelenumii}{}{\colorbox{CornflowerBlue!50}{\textbf{\alph{enumii}}}}

\NewDocumentEnvironment{solution}{}{%
    \RenewDocumentCommand{\qedsymbol}{}{$\blacksquare$}
    \begin{proof}[Solution]
}{\end{proof}}

\makeatletter
\newcommand*{\defeq}{\mathrel{\rlap{%
                     \raisebox{0.3ex}{$\m@th\cdot$}}%
                     \raisebox{-0.3ex}{$\m@th\cdot$}}%
                     =}
\makeatother

\begin{document} 

\section*{How to Use this Reviewer}
Hello! This is a compilation of solved exercises for module 3 of MATH 51.4. All of these exercises are taken straight from Aldrich and Cisco's course notes, so you can expect tests 
to be very similar to the items given. Some items are bound to be a little bit trickier than others, so I'll note when these items show up.\par Normal items will look like this:\begin{enumerate} 
    \item A very easy math problem. What's 1 + 1?
\end{enumerate} 
whereas difficult problems will be soulless, like this:\begin{enumerate}\setcounter{enumi}{1}
    \RenewDocumentCommand{\labelenumi}{}{\fcolorbox{magenta}{white}{\textbf{\arabic{enumi}}}}
    \item A very difficult math problem. Prove that $\displaystyle \binom{2n}{n} < 2^{2n-2},~\forall n \geq 5$ using induction. 
\end{enumerate} I might also include warnings in my \textbf{Nerd Interjections!}\par
\parindent=25pt \begin{minipage}[t]{.14\textwidth}
    \vspace{0pt}
    \includegraphics[width=2cm]{nerd_maddy.png}
\end{minipage}%
\fbox{
\begin{minipage}[t]{.76\textwidth}
    \vspace{0pt}
    \textbf{Nerd Interjection!}\footnote{Image from @Ellem\_\_ on Twitter.} These sections are for me to remind you of some necessary information to solve the problems, elaborate on 
    something that I think isn't all that clear with just pure math symbols, give a helpful theorem, be an annoying piece of shit, anything, really! Just think of it as a tips and tricks section. 
\end{minipage}%
}\parindent=0pt \par I also have another section called \textbf{Can we Prove it?} (unfortunately lacking a cute picture to go along with it; Mikh 
was nice enough to edit one up for me, but I haven't been able to format it in a way I like), where I include some interesting, not really necessary, but 
nonetheless relevant proofs. So far, these two are my only two gimmicks, but I might add more in the future.\par
\fbox{\begin{minipage}[t]{0.98\textwidth}
    \vspace{0pt} 
    \textbf{Can we Prove it?} This is just a random proof I yoinked from our homeworks.\begin{proof} 
        ($ \implies $) Let $ x \in (A \cap B) \setminus C $. Then, $ x \in (A \cap B)$ and $ x \notin C $. \\
        \phantom{($ \implies $)} Since $x \in (A \cap B)$, $ x \in A$ and $ x \in B$. \\
        \phantom{($ \implies $)} Since $x \in A$ and $x \notin C$, $x \in (A \setminus C) $. \\
        \phantom{($ \implies $)} Since $x \in B$ and $x \notin C$, $x \in (B \setminus C) $. \\
        \phantom{($ \implies $)} Thus, $x \in (A \setminus C) \cap (B \setminus C) $. \\ 
        \\
        ($ \impliedby $) Let $ x \in (A \setminus C) \cap (B \setminus C) $. Then, $ x \in (A \setminus C) $ and $ x \in (B \setminus C) $. \\ 
        \phantom{($ \impliedby $)} Since $ x \in (A \setminus C) $, $ x \in A $ and $ x \notin C $. \\
        \phantom{($ \impliedby $)} Since $ x \in (B \setminus C) $, $ x \in B $ and $ x \notin C $. \\
        \phantom{($ \impliedby $)} Since $ x \in A $ and $ x \in B $, $ x \in (A \cap B) $. \\
        \phantom{($ \impliedby $)} Thus, $ x \in (A \cap B) \setminus C $. \\
        \\ 
        Since both sides of the conditional are true, it holds that $ (A \cap B) \setminus C = (A \setminus C) \cap (B \setminus C) $. 
    \end{proof} 
\end{minipage}%
}\par
Finally, there are blue boxes to indicate when instructions aren't obvious from the question itself, or if there are similar items that can be grouped together.\par
\parindent=25pt 
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        For items \#7 to \#12, we need to reevaluate our life decisions.
    \end{minipage}
    }\parindent=0pt \par 
It's very important to note that this is a \textit{work in progress!} I am human, and I will make mistakes, and I cannot finish doing all the exercises within the span of one day. If you spot anything wrong, 
please feel free to message me; I will correct it as soon as possible.\par
As a final note, these are not replacements for the modules/paying attention in class, these are supplements for them. I won't explain all the topics here, and I'll assume that you at least have 
read the basics, so don't treat these reviewers as your only source of information. Our teachers spends a lot of time on the handouts, they're really good! (except when they're wrong) With that, though, I think 
I've covered all pertinent points. Good luck, and happy studying!

\section*{3.1.1: Linear combinations}
\textit{Some notes on notation: I'm not a big fan of the boldface lowercase letters representing matrices, particularly vectors, mostly because it's a little difficult to tell (and we love 
clarity here) so I'll be using the arrow on top instead to denote vectors.}\par
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        For each set of vectors \(V\) and given vector \(\overrightarrow{w}\), determine if \(\overrightarrow{w}\) can be expressed as a linear combination of the vectors in \(V\). 
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \item \(V = \begin{Bmatrix}
        \begin{pmatrix}
            1\\-1
        \end{pmatrix},\begin{pmatrix}
            2\\3
        \end{pmatrix}
    \end{Bmatrix}; \qquad \overrightarrow{w} = \begin{pmatrix}
        30\\30
    \end{pmatrix}\)\begin{solution}
        We need to figure out if there exist two coefficients \(k_1\) and \(k_2\) such that \(k_1\overrightarrow{v_1} + k_2\overrightarrow{v_2} = \overrightarrow{w}\).
        Expressing it in a linear equation like this, we can then solve for the coefficients using Gaussian elimination, like so\[
            \begin{pmatrix}
                1&2 \\ -1&3
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                30\\30
            \end{pmatrix} \Longleftrightarrow \begin{pmatrix}
                1&2 \\ 0&1
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                30\\12
            \end{pmatrix}.
        \] This tells us that \(k_2 =12\), and substituting this into the first row gives us \(k_1=6\). Thus, there exists a unique linear combination of vectors in \(V\) that we can express \(\overrightarrow{w}\) as. 
    \end{solution}
    \begin{minipage}{.14\textwidth}
        \vspace{0pt}
        \includegraphics[width=2cm]{nerd_maddy.png}
    \end{minipage}%
    \fbox{
    \begin{minipage}{.76\textwidth}
        \vspace{0pt}
        \textbf{Nerd Interjection!} The Gaussian elimination here is fairly straightforward since we're just dealing with two variables and two equations, so I won't bother mucking up the pages with all the steps. I might elaborate a little
        bit more later on, when we get to the sets with vectors in \(\mathbb{R}^3\), but for these first three at least, it shouldn't be too hard to see how we got from one step to the next.  
    \end{minipage}%
    }
    \item \(V = \begin{Bmatrix}
        \begin{pmatrix}
            1\\-2
        \end{pmatrix},\begin{pmatrix}
            -2\\4
        \end{pmatrix}
    \end{Bmatrix}; \qquad \overrightarrow{w} = \begin{pmatrix}
        -10\\20
    \end{pmatrix}\)\begin{solution}
        We need to figure out if there exist two coefficients \(k_1\) and \(k_2\) such that \(k_1\overrightarrow{v_1} + k_2\overrightarrow{v_2} = \overrightarrow{w}\).
        Expressing it in a linear equation like this, we can then solve for the coefficients using Gaussian elimination, like so:\[
            \begin{pmatrix}
                1&-2 \\ -2&4
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                -10\\20
            \end{pmatrix} \Longleftrightarrow \begin{pmatrix}
                1&-2 \\ 0&0
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                -10\\0
            \end{pmatrix}.
        \] This tells us that there are infinitely many solutions, and thus, infinitely many linear combinations of vectors in \(V\) that we can express \(\overrightarrow{w}\) as. If we let \(k_2\defeq r,~r\in\mathbb{R}\), then \(k_1 = 2r -10\).
    \end{solution}
    \item \(V = \begin{Bmatrix}
        \begin{pmatrix}
            1\\-2
        \end{pmatrix},\begin{pmatrix}
            -2\\4
        \end{pmatrix}
    \end{Bmatrix}; \qquad \overrightarrow{w} = \begin{pmatrix}
        1\\-3
    \end{pmatrix}\)\begin{solution}
        We need to figure out if there exist two coefficients \(k_1\) and \(k_2\) such that \(k_1\overrightarrow{v_1} + k_2\overrightarrow{v_2} = \overrightarrow{w}\).
        Expressing it in a linear equation like this, we can then solve for the coefficients using Gaussian elimination, like so:\[
            \begin{pmatrix}
                1&-2 \\ -2&4
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                1\\-3
            \end{pmatrix} \Longleftrightarrow \begin{pmatrix}
                1&-2 \\ 0&0
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                1\\-1
            \end{pmatrix}.
        \] This tells us that there is no solution, or that there is no possible linear combination of vectors in \(V\) that we can express \(\overrightarrow{w}\) as. Wow! Three for three on the three cases of solutions! That's totally not intentional. 
    \end{solution}
    \pagebreak
    \item \(V = \begin{Bmatrix}
        \begin{pmatrix}
            2\\-1\\3
        \end{pmatrix},\begin{pmatrix}
            5\\0\\4
        \end{pmatrix}
    \end{Bmatrix}; \qquad \overrightarrow{w} = \begin{pmatrix}
        -1\\-2\\2
    \end{pmatrix}\)\begin{solution}
        We need to figure out if there exist two coefficients \(k_1\) and \(k_2\) such that \(k_1\overrightarrow{v_1} + k_2\overrightarrow{v_2} = \overrightarrow{w}\).
        Expressing it in a linear equation like this, we can then solve for the coefficients using Gaussian elimination, like so:\[
            \begin{pmatrix}
                2&5\\-1&0\\3&4
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                -1\\-2\\2
            \end{pmatrix}.
        \] By inspection, though, we can see that from the second row, \(-k_1 = -2\), so \(k_1 = 2\).\footnote{LOL, I said I'd be more detailed with the Gaussian elimination but we don't even have to do it for these first two items. Love it!} Substituting this into either of the other two rows gives us \(k_2 = -1\). Thus, there exists a unique linear combination of vectors in \(V\) that 
        we can express \(\overrightarrow{w}\) as. 
    \end{solution}
    \item \(V = \begin{Bmatrix}
        \begin{pmatrix}
            2\\-1\\3
        \end{pmatrix},\begin{pmatrix}
            5\\0\\4
        \end{pmatrix}
    \end{Bmatrix}; \qquad \overrightarrow{w} = \begin{pmatrix}
        1\\1\\-1
    \end{pmatrix}\)\begin{solution}
        We need to figure out if there exist two coefficients \(k_1\) and \(k_2\) (I'm getting so bored of saying that) such that \(k_1\overrightarrow{v_1} + k_2\overrightarrow{v_2} = \overrightarrow{w}\). Then, \[
            \begin{pmatrix}
                2&5\\-1&0\\3&4
            \end{pmatrix}\begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                1\\1\\-1
            \end{pmatrix}.
        \] By inspection, we can see that from the second row, \(-k_1 = 1\), so \(k_1 = -1\). However, substituting this into the other two rows gives us different answers, namely \(k_2 = 0.6\) and \(k_2 = 0.5\).\ \(k_2\) can't have two values, 
        so this is a contradiction, implying that there is no solution, and that \(\overrightarrow{w}\) cannot be expressed as a linear combination of vectors in \(V\). 
    \end{solution}
    \item \(V = \begin{Bmatrix}
        \begin{pmatrix}
            2\\-1\\3
        \end{pmatrix},\begin{pmatrix}
            5\\0\\4
        \end{pmatrix},\begin{pmatrix}
            3\\1\\1
        \end{pmatrix}
    \end{Bmatrix}; \qquad \overrightarrow{w} = \begin{pmatrix}
        1\\-8\\12
    \end{pmatrix}\)\begin{solution}
        We need to figure out of there exist \textit{three} (YIPPIE!) coefficients \(k_1\), \(k_2\), and \(k_3\) such that \(k_1\overrightarrow{v_1} + k_2\overrightarrow{v_2} + k_3\overrightarrow{v_3} = \overrightarrow{w}\). Expressing it in a linear
        equation like this, we can then solve for the coefficients using Gaussian elimination, like so (let's actually go through the Gaussian elimination for this one):\begin{align*} 
            \begin{pmatrix}
                2&5&3\\-1&0&1\\3&4&1
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2\\k_3
            \end{pmatrix} &= \begin{pmatrix}
                1\\-8\\12
            \end{pmatrix} &\begin{matrix}\\2R_2 + R_1 \implies R_1\\3R_2 + R_3 \implies R_3 \end{matrix}&&\begin{pmatrix}
                0&5&5\\-1&0&1\\0&4&4
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2\\k_3
            \end{pmatrix} &= \begin{pmatrix}
                -15\\-8\\-12
            \end{pmatrix}\\
            &&  \begin{matrix}\\\frac{1}{5}R_1 \implies R_1\\\frac{1}{4}R_3 \implies R_3 \end{matrix}&&\begin{pmatrix}
                0&1&1\\-1&0&1\\0&1&1
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2\\k_3
            \end{pmatrix} &= \begin{pmatrix}
                -3\\-8\\-3
            \end{pmatrix}.
        \end{align*} We see here that there are two identical rows, which should already clue us in to the fact that there are infinitely many solutions. Thus, if we choose \(k_3 \defeq r,~r\in\mathbb{R}\), then \(k_2=-r-3\) and \(k_1=r+8\).
    \end{solution}
\end{enumerate}
\pagebreak
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        Each of the following sets of vectors \(\lbrace\overrightarrow{v_1},\overrightarrow{v_2}\rbrace\) below is special in that any vector \((x,y) \in \mathbb{R}^2 \) can be uniquely 
        expressed as a linear combination of \(\overrightarrow{v_1}\) and \(\overrightarrow{v_2}\). Find the \textit{coefficients} \(k_1\) and \(k_2\) in terms of \(x\) and \(y\) such that\[
            k_1\overrightarrow{v_1} + k_2\overrightarrow{v_2} = \begin{pmatrix}
                x\\y
            \end{pmatrix}.
        \]
    \end{minipage}
    }\end{center}
\begin{enumerate}
    \setcounter{enumi}{6}
    \item \(\overrightarrow{v_1} = \begin{pmatrix}
        4\\3
    \end{pmatrix},\qquad\overrightarrow{v_2} = \begin{pmatrix}
        1\\1
    \end{pmatrix}\)\begin{solution}
        Let \((x,y)\) be any arbitrary vector in \(\mathbb{R}^2\). Setting up the linear equation gives us\[
            \begin{pmatrix}
                4&1\\3&1
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x\\y
            \end{pmatrix} \qquad R_1 - R_2 \implies R_2 \qquad \begin{pmatrix}
                4&1 \\ 1&0 
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x \\x-y
            \end{pmatrix},
        \] so \(k_1 = x-y\). Substituting this into the first row gives us \(k_2 = 4y - 3x\). 
    \end{solution}
    \item \(\overrightarrow{v_1} = \begin{pmatrix}
        7\\2
    \end{pmatrix},\qquad\overrightarrow{v_2} = \begin{pmatrix}
        3\\1
    \end{pmatrix}\)\begin{solution}
        Let \((x,y)\) be any arbitrary vector in \(\mathbb{R}^2\). Setting up the linear equation gives us\[
            \begin{pmatrix}
                7&3\\2&1
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x\\y
            \end{pmatrix} \qquad R_1 - 3R_2 \implies R_2 \qquad \begin{pmatrix}
                7&3 \\ 1&0 
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x \\x-3y
            \end{pmatrix},
        \] so \(k_1 = x-3y\). Substituting this into the first row gives us \(k_2 = 7y - 2x\).
    \end{solution}
    \item \(\overrightarrow{v_1} = \begin{pmatrix}
        3\\-1
    \end{pmatrix},\qquad\overrightarrow{v_2} = \begin{pmatrix}
        5\\2
    \end{pmatrix}\)\begin{solution}
        Let \((x,y)\) be any arbitrary vector in \(\mathbb{R}^2\). Setting up the linear equation gives us\[
            \begin{pmatrix}
                3&5\\-1&2
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x\\y
            \end{pmatrix} \qquad R_1 + 3R_2 \implies R_1 \qquad \begin{pmatrix}
                0&11 \\ -1&2 
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x+3y \\y
            \end{pmatrix},
        \] so \(k_2 = \dfrac{1}{11}(x+3y)\). Substituting this into the first row gives us \(k_1 = \dfrac{1}{11}(2x-5y)\).
    \end{solution}
    \item \(\overrightarrow{v_1} = \begin{pmatrix}
        5\\-1
    \end{pmatrix},\qquad\overrightarrow{v_2} = \begin{pmatrix}
        -2\\3
    \end{pmatrix}\)\begin{solution}
        Let \((x,y)\) be any arbitrary vector in \(\mathbb{R}^2\). Setting up the linear equation gives us\[
            \begin{pmatrix}
                5&-2\\-1&3
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x\\y
            \end{pmatrix} \qquad 5R_2 + R_1 \implies R_2 \qquad \begin{pmatrix}
                5&-2 \\ 0&13 
            \end{pmatrix} \begin{pmatrix}
                k_1\\k_2
            \end{pmatrix} = \begin{pmatrix}
                x \\x+5y
            \end{pmatrix},
        \] so \(k_2 = \dfrac{1}{13}(x+5y)\). Substituting this into the first row gives us \(k_1 = \dfrac{1}{13}(3x + 2y)\).\footnote{Yes, these answers with fractions of \textit{prime numbers larger than 10} are correct, I double-checked.}
    \end{solution}
\end{enumerate}
\pagebreak 

\section*{3.1.2: Norm and dot product}
\textit{We learned about this stuff in calculus so it shouldn't be that new, but to be honest I've forgotten everything since vectors were an afterthought in 30.24, so here's a refresher, I guess.}
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        For each of the following vectors \(\overrightarrow{v}\) find a unit vector \(\hat{v}\) pointing in the same direction as \(\overrightarrow{v}\). 
    \end{minipage}
    }
\end{center}

\begin{minipage}{.14\textwidth}
    \vspace{0pt}
    \includegraphics[width=2cm]{nerd_maddy.png}
\end{minipage}%
\fbox{
\begin{minipage}{.76\textwidth}
    \vspace{0pt}
    \textbf{Nerd Interjection!} To find a unit vector pointing in the same direction, we just divide the vector by its norm. Recall that the norm of a vector in \(\mathbb{R}^n\) is given by \[
        \big|\!\big|\overrightarrow{v}\big|\!\big| = \sqrt{v_1^2,+ v_2^2 + \cdots + v_n^2}. 
    \]
\end{minipage}%
}
\begin{enumerate}
    \setcounter{enumi}{10} 
    \item \(\overrightarrow{v} = (4,3)~\)\footnote{\textit{Norm}ally the lack of internal consistency with how vectors are represented would be killing me but I actually like the diversification of math notation. She says, after proclaiming a bold dislike (pun not intended)
    for boldface letters representing vectors. Maybe I need to do some self-reflection.}\begin{solution}
        The norm of \(\overrightarrow{v}\) is \(\sqrt{4^2 + 3^2} = 5\). Thus, \(\hat{v} = \biggl(\dfrac{4}{5}, \dfrac{3}{5}\biggl)\). 
    \end{solution}
    \item \(\overrightarrow{v} = (0,1)\)\begin{solution}
        The norm of \(\overrightarrow{v}\) is \(\sqrt{0^2 + 1^2} = 1\). Thus, \(\overrightarrow{v}\) is already a unit vector, and \(\hat{v} = \overrightarrow{v} = (0,1)\). 
    \end{solution}
    \item \(\overrightarrow{v} = (5,\sqrt{5},0)\)\begin{solution}
        The norm of \(\overrightarrow{v}\) is \(\sqrt{5^2 + {\sqrt{5}}^2 + 0^2} = \sqrt{30}\). Thus, \(\hat{v} = \biggl(\dfrac{5}{\sqrt{30}}, \sqrt{\dfrac{1}{6}}, 0\biggl)\). 
    \end{solution}
    \item \(\overrightarrow{v} = (-1,4,1)\)\begin{solution}
        The norm of \(\overrightarrow{v}\) is \(\sqrt{{(-1)}^2 + 4^2+ 1^2} = 3\sqrt{2}\). Thus, \(\hat{v} = \biggl(-\dfrac{1}{3\sqrt{2}}, \dfrac{4}{3\sqrt{2}}, \dfrac{1}{3\sqrt{2}}\biggl)\). 
    \end{solution}
    \item \(\overrightarrow{v} = (0,2,1,-1)\)\begin{solution}
        The norm of \(\overrightarrow{v}\) is \(\sqrt{0^2 + 2^2 + 1^2 + {(-1)}^2} = \sqrt{6}\). Thus, \(\hat{v} = \biggl(0, \dfrac{2}{\sqrt{6}}, \dfrac{1}{\sqrt{6}}, -\dfrac{1}{\sqrt{6}}\biggl)\). 
    \end{solution}
    \item \(\overrightarrow{v} = (1,1,2,2)\)\begin{solution}
        The norm of \(\overrightarrow{v}\) is \(\sqrt{1^2 + 1^2 + 2^2 + 2^2} = \sqrt{10}\). Thus, \(\hat{v} = \biggl(\dfrac{1}{\sqrt{10}}, \dfrac{1}{\sqrt{10}}, \dfrac{2}{\sqrt{10}}, \dfrac{2}{\sqrt{10}}\biggl)\).
    \end{solution}
\end{enumerate}
\begin{minipage}{.14\textwidth}
    \vspace{0pt}
    \includegraphics[width=2cm]{nerd_maddy.png}
\end{minipage}%
\fbox{
\begin{minipage}{.76\textwidth}
    \vspace{0pt}
    \textbf{Nerd Interjection!} Some formulas for vectors in \(\mathbb{R}^n\) (needed for the next page):\begin{gather*}
        d(\overrightarrow{u}, \overrightarrow{v}) = \big|\!\big| \overrightarrow{u} - \overrightarrow{v} \big|\!\big| = \sqrt{{(u_1 - v_1)}^2 + {(u_2 - v_2)}^2 +\cdots +{(u_n - v_n)}^2} \\
        \overrightarrow{u} \cdot \overrightarrow{v} = u_1 v_1 + u_2 v_2 + \cdots + u_n v_n \\ 
        \theta = \cos^{-1} \Biggl(\frac{\overrightarrow{u} \cdot \overrightarrow{v}}{\big|\!\big|\overrightarrow{u}\big|\!\big| \big|\!\big|\overrightarrow{v}\big|\!\big|}\Biggr)
    \end{gather*}
\end{minipage}%
}
\pagebreak
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        For each of the following vectors in items \#17 to \#20 \(\overrightarrow{u}\) and \(\overrightarrow{v}\), find the distance between the two of them, the dot product of the two of them, and the angle between the two of them. 
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \setcounter{enumi}{16}
    \item \(\overrightarrow{u} = (1,-1), \overrightarrow{v} = (-1,1)\)\begin{solution}
        The distance between the vectors is \(\sqrt{{\bigl(1-(-1)\bigr)}^2 + {(-1 -1)}^2} = 2\sqrt{2}\).\par
        The dot product of the vectors is \(1(-1) + (-1)1 = -2\).\par 
        The angle between the vectors is \(\cos^{-1} \biggl(\dfrac{-2}{\sqrt{2}\cdot\sqrt{2}}\biggr) = \cos^{-1} (-1) = \pi~\text{rad}\) or \(180^{\circ}\). 
    \end{solution}
    \item \(\overrightarrow{u} = (0,1,-1,2), \overrightarrow{v} = (1,1,2,2)\)\begin{solution}
        The distance between the vectors is \(\sqrt{{(0-1)}^2 + {(1 -1)}^2 + {(-1 -2)}^2 + {(2 -2)}^2} = \sqrt{10}\).\par
        The dot product of the vectors is \(0(1) + 1(1) + (-1)2 + 2(2) = 3\).\par 
        The angle between the vectors is \(\cos^{-1} \biggl(\dfrac{3}{\sqrt{6}\cdot\sqrt{10}}\biggr) = \cos^{-1} \biggl(\dfrac{3}{\sqrt{60}}\biggr) \approx 1.173~\text{rad}\) or \(67.213^{\circ}\).\footnote{Cheeky little Aldrich and Cisco making the vectors 4D so we can't
        just graph them in 2D or 3D space and visually check our answers. ``Just use 3B1B's method for visualizing quaternions!'' Be quiet, Thanie.} 
    \end{solution}
    \item \(\overrightarrow{u} = (0,1,0,1), \overrightarrow{v} = (3,3,3,3)\)\begin{solution}
        The distance between the vectors is \(\sqrt{{(0-3)}^2 + {(1 -3)}^2 + {(0 -3)}^2 + {(1 -3)}^2} = \sqrt{26}\).\par
        The dot product of the vectors is \(0(3) + 1(3) + 0(3) + 1(3) = 6\).\par 
        The angle between the vectors is \(\cos^{-1} \biggl(\dfrac{6}{\sqrt{2}\cdot6}\biggr) = \cos^{-1} \biggl(\dfrac{1}{\sqrt{2}}\biggr) = \dfrac{\pi}{4}~\text{rad}\) or \(45^{\circ}\).
    \end{solution}
    \item \(\overrightarrow{u} = (1,\sqrt{2},-1,\sqrt{2}), \overrightarrow{v} = (1,-\frac{1}{\sqrt{2}},1,-\frac{1}{\sqrt{2}})\)\begin{solution}
        The distance between the vectors is\[
            \sqrt{{(1-1)}^2 + {\Biggl(\sqrt{2} - \biggl(-\frac{1}{\sqrt{2}}\biggr)\Biggr)}^2 + {(-1-1)}^2 + {\Biggl(\sqrt{2} - \biggl(-\frac{1}{\sqrt{2}}\biggr)\Biggr)}^2} =  \sqrt{13}.
        \]
        The dot product of the vectors is \(1(1) + \sqrt{2}\biggl(\dfrac{1}{\sqrt{2}}\biggr) + (-1)1 + \sqrt{2}\biggl(\dfrac{1}{\sqrt{2}}\biggr) = 2\).\par 
        The angle between the vectors is \(\cos^{-1} \biggl(\dfrac{2}{\sqrt{6}\cdot\sqrt{3}}\biggr) = \cos^{-1} \biggl(\dfrac{2}{3\sqrt{2}}\biggr) \approx 1.080~\text{rad} \) or \(61.874^{\circ}\). 
    \end{solution}
    \item Consider the vector \(\overrightarrow{v} = (-1,3,0,4)\). Find a vector \(\overrightarrow{u}\) which is twice as long as \(\overrightarrow{v}\) and is pointing in the opposite direction.\begin{solution}
        We can start by finding the vector that is pointing in the opposite direction as \(\overrightarrow{v}\) but with the same length, which we can get by negating \(\overrightarrow{v}\). Then, we just multiply this vector by 2 
        to make its magnitude twice as much. Thus, the vector we want is \(\overrightarrow{u} = (2,-6,0,-8)\).\par 
        We can verify this answer by checking the norm of both vectors. The norm of \(\overrightarrow{v}\) is \(\sqrt{{(-1)}^2 + 3^2 + 0^2 + 4^2} = \sqrt{26}\), while the norm of \(\overrightarrow{u}\) is \(\sqrt{2^2 + {(-6)}^2 + 0^2 + {(-8)}^2} = 2\sqrt{26}\), 
        which is indeed twice the norm of \(\overrightarrow{v}\).
    \end{solution}
\end{enumerate}
\pagebreak

\section*{3.1.3: Standard matrices of linear transformations}
\textit{Oh no! Drawings! Fuck! Even if it's kind of a pain, I'd much rather do all the graphs in \LaTeX{} than use some external graphing software and take screenshots. I'm pretty familiar with tikz anyway (waw). }
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        For each of the following linear transformations \(T: \mathbb{R}^2 \to \mathbb{R}^2\), sketch and label the following six vectors. Sketch all the premiages in one axis and then all the images in another axis.\par 
        \textit{Preimages: } \(\mathbf{e}_1\), \(\mathbf{e}_2\), \(\mathbf{e}_1 + \mathbf{e_2}~\); \textit{Images: } \(T(\mathbf{e}_1)\), \(T(\mathbf{e}_2)\), \(T(\mathbf{e}_1 + \mathbf{e_2})\)
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \setcounter{enumi}{21}
    \item \(T(x,y) = (x,-y)\)
    \item \(T(x,y) = (-x,y)\)
    \item \(T(x,y) = (x,x+y)\)
    \item \(T(x,y) = (x+y,y)\)
    \item \(T(x,y) = (-2x,3y)\)
    \item \(T(x,y) = (x,0)\)
\end{enumerate}
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        State the domain and codomain of each of the following linear transformations \(T\), then find the standard matrix for \(T\).
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \setcounter{enumi}{27}
    \item \(T(x,y) = (x+2y, x-2y)\)
    \item \(T(x,y) = (2x-3y,x-y,y-4x)\)
    \item \(T(x,y,z) = (x+y, x-y, z-x)\)
    \item \(T(x,y) = (5x+y,0,4x-5y)\)
    \item \(T(x,y,z) = (3x-2z,2y-z)\)
    \item \(T(x_1,x_2,x_3,x_4) = (x_4,x_3,x_1 + x_2,x_1)\)
    \item \(T(x_1,x_2,x_3,x_4) = (0,0,0,0)\)
    \item \(T(x,y) = (x+2y, x-2y, x,y)\)
\end{enumerate}
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        Use a counterexample to show that the following functions are not linear transformations. 
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \setcounter{enumi}{35}
    \item \(T(x,y) = (x^2,y)\)
    \item \(T(x,y) = (x,y,xy)\)
\end{enumerate}
\pagebreak 

\section*{3.2.1: Transformations on the unit square}
\textit{More drawings?! It's like they want me to suffer. } 
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        Given the following matrices \(A\) and transformations \(T\), sketch the effect of the corresponding linear transformation \(T_A(x,y)\) on the unit square. 
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \setcounter{enumi}{37}
    \item \(\begin{bmatrix}
        -1&0 \\ 1&-1
    \end{bmatrix}\)
    \item \(\begin{bmatrix}
        0&1 \\ 2&1
    \end{bmatrix}\)
    \item \(T(x,y) = (x+y,y)\)
    \item \(T(x,y) = (y-x,y+x)\)
\end{enumerate}
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        Given how the following linear transformations act on the unit square, identify the standard matrix \(A\) associated with this transformation, and also give an explicit formula
        for the output of \(T_A(x,y)\) in terms of \((x,y)\). 
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \setcounter{enumi}{41}
    \item image
    \item image
\end{enumerate}
\begin{center}
    \colorbox{CornflowerBlue!50}{
    \begin{minipage}[c]{0.9\textwidth}
        \centering
        For items \#44 to \#48, all rotations mentioned are counterclockwise rotations with respect to the origin. 
    \end{minipage}
    }
\end{center}
\begin{enumerate}
    \setcounter{enumi}{43}
    \item Let \(\overrightarrow{u}\) and \(\overrightarrow{v}\) be perpendicular 2D vectors.\footnote{Oh, so now they use the arrow notation.} Use the rotation matrix to verify that they will still be perpendicular even if you rotate both 
    by the same amount \(\theta\). 
    \item Let \(\overrightarrow{u}\) and \(\overrightarrow{v}\) be perpendicular 2D vectors. Use the rotation matrix to verify that their dot product is preserved even if you rotate both 
    by the same amount \(\theta\). 
    \item Let \(\overrightarrow{u}\) be a 2D vector. Use the rotation matrix to verify that its length is preserved even if you rotate it by some angle \(\theta\). 
    \item Let \(\overrightarrow{u}\) and \(\overrightarrow{v}\) be 2D vectors. Verify that the angle \(\alpha\) between them is preserved even if you rotate both by the same amount \(\theta\). 
    \item Let \(\overrightarrow{u}\) and \(\overrightarrow{v}\) be 2D vectors. Verify that projecting \(\overrightarrow{u}\) onto \(\overrightarrow{v}\) and then rotating the projection by \(\theta\) gives
    the same result as rotating \(\overrightarrow{u}\) and \(\overrightarrow{v}\) by \(\theta\) and then projecting the rotated \(\overrightarrow{u}\) onto the rotated \(\overrightarrow{v}\). 
    \item Show that:\begin{enumerate}
        \item reflecting across the line \(y = x\)
        \item and then reflectiong across the line \(x=0\)
    \end{enumerate} produces the same result as a \(90^\circ\) counterclockwise rotation.
    \item Show that:\begin{enumerate}
        \item reflecting across the line \(y=x\)
        \item and then reflectiong across the line \(y = -x\) 
    \end{enumerate} produces the same result as a \(180^\circ\) rotation. 
    \item Show that:\begin{enumerate}
        \item rotating \(90^\circ\) counterclockwise
        \item and then reflecting across the line \(x=0\)
    \end{enumerate} gives the same result as\begin{enumerate}
        \item reflecting across the line \(x=0\)
        \item and then rotating \(90^\circ\) \textbf{clockwise}.
    \end{enumerate}
    \begin{minipage}{.14\textwidth}
        \vspace{0pt}
        \includegraphics[width=2cm]{nerd_maddy.png}
    \end{minipage}%
    \fbox{
    \begin{minipage}{.76\textwidth}
        \vspace{0pt}
        \textbf{Nerd Interjection!} I've marked the next few items as difficult, but after the second LT, I don't trust Aldrich enough to not give them as test items, particularly the last three. The trigonometric identities 
        you can probably get away with ignoring, but it might be good to look at the algebra and logic in items \#53 to \#55. I'll try my best to explain.  
    \end{minipage}%
    }
    \RenewDocumentCommand{\labelenumi}{}{\fcolorbox{magenta}{white}{\textbf{\arabic{enumi}}}}
    \item Use rotation matrices to prove the following trigonometric identities:\begin{enumerate}
        \RenewDocumentCommand{\labelenumii}{}{\fcolorbox{CornflowerBlue!50}{white}{\textbf{\alph{enumii}}}}
        \item \(\sin(\alpha + \beta) = \sin\alpha\cos\beta + \cos\alpha\sin\beta\)\begin{proof}
            Let \(A\) be the matrix for rotating a vector by an angle \(\alpha\) and \(B\) be the matrix for rotating by an angle \(\beta\). Finally, let \(X\) be the matrix for rotating by their sum, \(\alpha + \beta\). Then,\[
                A = \begin{bmatrix}
                    \cos\alpha&-\sin\alpha \\ \sin\alpha&\cos\alpha
                \end{bmatrix};~B = \begin{bmatrix}
                    \cos\beta&-\sin\beta \\ \sin\beta&\cos\beta
                \end{bmatrix};~X =  \begin{bmatrix}
                    \cos(\alpha + \beta)&-\sin(\alpha + \beta) \\ \sin(\alpha+\beta)&\cos(\alpha + \beta)
                \end{bmatrix}.
            \] We know that rotation by \(\alpha\) followed by rotation by \(\beta\) (or vice versa) is the same as rotating by their sum. This in turn means, that if we multiply \(A\) and \(B\) by any given vector \(\mathbf{v}\) in \(\mathbb{R}^2\), then the effect on \(\mathbf{v}\)
            should be the same as if we had just multiplied \(X\) by it instead. Thus, \(BA\,\mathbf{v} = X\mathbf{v}\), so \(BA = X\). Performing the matrix multiplication, we have\begin{align*}
                &\begin{bmatrix}
                    \cos\alpha&-\sin\alpha \\ \sin\alpha&\cos\alpha
                \end{bmatrix} \\
                \begin{bmatrix}
                    \cos\beta&-\sin\beta \\ \sin\beta&\cos\beta
                \end{bmatrix} & \begin{bmatrix}
                    \cos\alpha\cos\beta - \sin\alpha\sin\beta&-\sin\alpha\cos\beta-\cos\alpha\sin\beta \\ 
                    \cos\alpha\sin\beta + \sin\alpha\cos\beta& -\sin\alpha\sin\beta + \cos\alpha\cos\beta
                \end{bmatrix}.
            \end{align*} Setting this to be equal to \(X\) and rearranging some terms,\[
                \begin{bmatrix}
                    \cos\alpha\cos\beta - \sin\alpha\sin\beta&-\sin\alpha\cos\beta-\cos\alpha\sin\beta \\ 
                    \colorbox{Periwinkle!42}{\(\sin\alpha\cos\beta + \cos\alpha\sin\beta\)}& -\sin\alpha\sin\beta + \cos\alpha\cos\beta
                \end{bmatrix} = \begin{bmatrix}
                    \cos(\alpha + \beta)&-\sin(\alpha + \beta) \\ \colorbox{Periwinkle!42}{\(\sin(\alpha+\beta)\)}&\cos(\alpha + \beta)
                \end{bmatrix} 
            \] gives us \(\sin(\alpha + \beta) = \sin\alpha\cos\beta + \cos\alpha\sin\beta\), which proves the identity. 
        \end{proof}
        \item \(\sin(\alpha - \beta) = \sin\alpha\cos\beta - \cos\alpha\sin\beta\)\begin{proof}
            Taking \(A\) from the previous item, let \(B^-\) be the matrix for rotating an angle by \(-\beta\) (in other words, \(\beta\) in the other direction, clockwise). Finally, let \(X^-\) be the matrix for rotating by their sum, \(\alpha -\beta\). Then, 
            (Recall that \(\sin(-\theta) = -\sin\theta\) and \(\cos(-\theta) = \cos\theta\).)\[
                A = \begin{bmatrix}
                    \cos\alpha&-\sin\alpha \\ \sin\alpha&\cos\alpha
                \end{bmatrix};~B^- = \begin{bmatrix}
                    \cos\beta&\sin\beta \\ -\sin\beta&\cos\beta
                \end{bmatrix};~X^- =  \begin{bmatrix}
                    \cos(\alpha - \beta)&-\sin(\alpha - \beta) \\ \sin(\alpha-\beta)&\cos(\alpha - \beta)
                \end{bmatrix}.
            \] We know that rotation by \(\alpha\) followed by rotation by \(-\beta\) (or vice versa) is the same as rotating by their sum. Thus, by similar reasoning as \textbf{a} above, \(B^-A = X^-\). Performing the matrix multiplication, we have\begin{align*} 
                &\begin{bmatrix}
                    \cos\alpha&-\sin\alpha \\ \sin\alpha&\cos\alpha
                \end{bmatrix} \\
                \begin{bmatrix}
                    \cos\beta&\sin\beta \\ -\sin\beta&\cos\beta
                \end{bmatrix} & \begin{bmatrix}
                    \cos\alpha\cos\beta + \sin\alpha\sin\beta&-\sin\alpha\cos\beta+\cos\alpha\sin\beta \\ 
                    -\cos\alpha\sin\beta + \sin\alpha\cos\beta& \sin\alpha\sin\beta + \cos\alpha\cos\beta
                \end{bmatrix}.
            \end{align*} Setting this to be equal to \(X\) and rearranging some terms, \[
                \begin{bmatrix}
                    \cos\alpha\cos\beta + \sin\alpha\sin\beta&-\sin\alpha\cos\beta+\cos\alpha\sin\beta \\ 
                    \colorbox{Periwinkle!42}{\(\sin\alpha\cos\beta -\cos\alpha\sin\beta\)} & \sin\alpha\sin\beta + \cos\alpha\cos\beta
                \end{bmatrix} = \begin{bmatrix}
                    \cos(\alpha - \beta)&-\sin(\alpha - \beta) \\ \colorbox{Periwinkle!42}{\(\sin(\alpha-\beta)\)}&\cos(\alpha - \beta)
                \end{bmatrix}
            \] gives us \(\sin(\alpha - \beta) = \sin\alpha\cos\beta - \cos\alpha\sin\beta\), which proves the identity. 
        \end{proof}
        \item \(\cos(\alpha + \beta) = \cos\alpha\cos\beta - \sin\alpha\sin\beta\)\begin{proof}
            From \textbf{a}, we have\[
                \begin{bmatrix}
                    \colorbox{Periwinkle!42}{\(\cos\alpha\cos\beta - \sin\alpha\sin\beta\)}&-\sin\alpha\cos\beta-\cos\alpha\sin\beta \\ 
                    \sin\alpha\cos\beta + \cos\alpha\sin\beta& -\sin\alpha\sin\beta + \cos\alpha\cos\beta
                \end{bmatrix} = \begin{bmatrix}
                    \colorbox{Periwinkle!42}{\(\cos(\alpha + \beta)\)}&-\sin(\alpha + \beta) \\ \sin(\alpha+\beta)&\cos(\alpha + \beta)
                \end{bmatrix},
            \] so \(\cos(\alpha + \beta) = \cos\alpha\cos\beta - \sin\alpha\sin\beta\), which proves the identity. 
        \end{proof}
        \item \(\cos(\alpha - \beta) = \cos\alpha\cos\beta + \sin\alpha\sin\beta\)\begin{proof}
            From \textbf{b}, we have\[
                \begin{bmatrix}
                    \colorbox{Periwinkle!42}{\(\cos\alpha\cos\beta + \sin\alpha\sin\beta\)}&-\sin\alpha\cos\beta+\cos\alpha\sin\beta \\ 
                    \sin\alpha\cos\beta - \cos\alpha\sin\beta& \sin\alpha\sin\beta + \cos\alpha\cos\beta
                \end{bmatrix} = \begin{bmatrix}
                    \colorbox{Periwinkle!42}{\(\cos(\alpha - \beta)\)}&-\sin(\alpha - \beta) \\ \sin(\alpha-\beta)&\cos(\alpha - \beta)
                \end{bmatrix},
            \] so \(\cos(\alpha - \beta) = \cos\alpha\cos\beta + \sin\alpha\sin\beta\), which proves the identity. 
        \end{proof}
    \end{enumerate}
    \item Let \(T(x,y)\) be a transformation that takes in a point \((x,y)\) and reflects it across the line that is a \(\theta\) counterclockwise rotation away from the positive \(x\)-axis. 
    Find the standard matrix for \(T\). (This is called the reflection matrix.)
    \item Use the reflection matrix to verify that every reflection is its own inverse. 
    \item Show that, in general, the composition of any two reflections correspond to some rotation. If the reflections are represented using angles \(\alpha\) and \(\beta\), express the angle of rotation in terms of \(\alpha\) and \(\beta\). 
\end{enumerate}
\pagebreak 

\section*{3.2.2: Orthogonality and projection}
\textit{blah blah blah} 
\pagebreak 

\section*{3.2.3: Spanning sets}
\textit{blah blah blah}

\end{document}